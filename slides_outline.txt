slides_outline

Title

Background
	

Data Science Problem
	What are you trying to predict?

		This model is trying to predict the level of similarity of a piece of unseen text of any length to a corpus of 30 historic works of philosophy from 20 authors.

	Why are you doing it? Who cares?

		Artificial Intelligence faces key limitation on abstract concepts, so tools to assist with this in any NLP modeling may prove useful.  Enabling models to better process meaning in its comparisons will make NLP models stronger.

	What are some predictions your model has made? Where they any good?
		Accuracy on:
			Self
			Test Data
			Bumper Stickers

	What will you use it for in the future? Are there limitations or risks?

		Limitations are around AI
		Limited corpora, slow processing speed with GPU
			2 hours to process train corpora

		Subjectivity of subject matter

		Risk is skynet AI takeover
		Simpler risk is abstract meaning is impossible for non-quantum computers - so much of philosophy revolves around the paradoxes of being
		"what is mind? no matter... what is matter? nevermind..."  Binary logic does not always apply - this could skew recognition towards "rationalist" thinkers - the concepts must make sense logically - and away from empirical thinkers - something must be seen to be believed. 

	Do not use technical terms unless you can clearly and succinctly define them.

Approach to Modeling
	Data
		30 works by 20 philosophers throughout history
		Gutenberg Project - free text files
	EDA
		Use keywords to mark start and end of text to parse

		Break into paragraphs, then sentences, while tracking position in the entire work

		Lemmatize, stopwords
	LDA
		"Latent Dirichlet Analysis"
		Probability-based Predictor
		Optimize for Coherence, Perplexity

	Word2Vec
		Topic Label Inference
		Built off large sets of text, create PCA vectors to map mathematical relationships between words

	Doc2Vec
		Meaning of Sentences and Paragraphs
		Vectorize multi-word corpora based on math relationships

	Models
		Multiclass Classifiers
			Naive Bayes
				Probabilistic Predictor
			
			Logistic Regression
				Linear model
				Interpretability
				Top terms
			RNN
				3 layers and multiple epochs to create function reflecting data and results


Findings
	Philosophy is difficult for humans to understand by definition, so training models on abstract data was expected to be challenging

	Most/Least predictable
	by sentence/paragraph




