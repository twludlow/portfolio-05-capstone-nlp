{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Philosophical Factors for NLP\n",
    "**_Measuring Similarity to Philosophical Concepts in Text Data_**\n",
    "\n",
    "## Thomas W. Ludlow, Jr.\n",
    "**General Assembly Data Science Immersive DSI-NY-6**\n",
    "\n",
    "**February 12, 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4 - Multiclass Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**4.1 Data Preparation**](#4.1-Data-Preparation)\n",
    "- [4.1.1 Define X and y](#4.1.1-Define-X-and-y)\n",
    "- [4.1.2 Standardize and Weight](#4.1.2-Standardize-and-Weight)\n",
    "\n",
    "[**4.2 Logistic Regression**](#4.2-Logistic-Regression)\n",
    "- [4.2.1 Logistic Regression Assembly](#4.2.1-Logistic-Regression-Assembly)\n",
    "- [4.2.2 Logistic Regression Optimization](#4.2.2-Logistic-Regression-Optimization)\n",
    "\n",
    "[**4.3 Recurrent Neural Net**](#4.4-Recurrent-Neural-Net)\n",
    "- [4.3.1 Keras FFRNN Assembly](#4.4.1-Keras-FFRNN-Assembly)\n",
    "- [4.3.2 Keras FFRNN Optimization](#4.4.2-Keras-FFRNN-Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Python Data Science\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Natural Language Processing\n",
    "import spacy\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, ldamulticore, CoherenceModel\n",
    "\n",
    "# Modeling Prep\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Neural Net\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Override deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train = pd.read_csv('../data_vec/prep_train.csv')\n",
    "prep_test = pd.read_csv('../data_vec/prep_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932, 99)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_vec_0</th>\n",
       "      <th>s_vec_1</th>\n",
       "      <th>s_vec_2</th>\n",
       "      <th>s_vec_3</th>\n",
       "      <th>s_vec_4</th>\n",
       "      <th>s_vec_5</th>\n",
       "      <th>s_vec_6</th>\n",
       "      <th>s_vec_7</th>\n",
       "      <th>s_vec_8</th>\n",
       "      <th>s_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>p9_lda_civil</th>\n",
       "      <th>p10_lda_deadites</th>\n",
       "      <th>p11_lda_idea</th>\n",
       "      <th>p12_lda_love</th>\n",
       "      <th>p13_lda_sense</th>\n",
       "      <th>p14_lda_biomolecular</th>\n",
       "      <th>p15_lda_thee</th>\n",
       "      <th>a_num</th>\n",
       "      <th>p_num</th>\n",
       "      <th>s_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.010836</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.805130</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000672</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>-0.008325</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.805130</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>-0.015351</td>\n",
       "      <td>-0.012835</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.805130</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.004347</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>-0.013354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.736205</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005489</td>\n",
       "      <td>-0.004147</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.011614</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.735830</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    s_vec_0   s_vec_1   s_vec_2   s_vec_3   s_vec_4   s_vec_5   s_vec_6  \\\n",
       "0  0.005141  0.007563 -0.005119  0.003487  0.014759 -0.000401 -0.013146   \n",
       "1  0.000672 -0.008255  0.004202  0.012191 -0.008325  0.010428 -0.010309   \n",
       "2  0.009192  0.003800  0.004282  0.003132  0.009840  0.002502 -0.015351   \n",
       "3  0.012862  0.005095  0.007222 -0.000288  0.005181  0.011893 -0.000838   \n",
       "4  0.005489 -0.004147 -0.003460 -0.008962  0.004228 -0.000990 -0.011614   \n",
       "\n",
       "    s_vec_7   s_vec_8   s_vec_9  ...    p9_lda_civil  p10_lda_deadites  \\\n",
       "0 -0.010836  0.013186  0.000359  ...        0.012991          0.012991   \n",
       "1  0.007246  0.000948  0.013675  ...        0.012991          0.012991   \n",
       "2 -0.012835  0.005541 -0.002684  ...        0.012991          0.012991   \n",
       "3 -0.004347  0.000892 -0.013354  ...        0.013657          0.013657   \n",
       "4 -0.008368  0.003744  0.005757  ...        0.013657          0.013657   \n",
       "\n",
       "   p11_lda_idea  p12_lda_love  p13_lda_sense  p14_lda_biomolecular  \\\n",
       "0      0.805130      0.012991       0.012991              0.012991   \n",
       "1      0.805130      0.012991       0.012991              0.012991   \n",
       "2      0.805130      0.012991       0.012991              0.012991   \n",
       "3      0.013657      0.013657       0.736205              0.013657   \n",
       "4      0.013657      0.013657       0.735830              0.013657   \n",
       "\n",
       "   p15_lda_thee  a_num  p_num  s_num  \n",
       "0      0.012991      0      0      0  \n",
       "1      0.012991      0      0      1  \n",
       "2      0.012991      0      0      2  \n",
       "3      0.013657      0      1      0  \n",
       "4      0.013657      0      1      1  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935, 99)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_vec_0</th>\n",
       "      <th>s_vec_1</th>\n",
       "      <th>s_vec_2</th>\n",
       "      <th>s_vec_3</th>\n",
       "      <th>s_vec_4</th>\n",
       "      <th>s_vec_5</th>\n",
       "      <th>s_vec_6</th>\n",
       "      <th>s_vec_7</th>\n",
       "      <th>s_vec_8</th>\n",
       "      <th>s_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>p9_lda_civil</th>\n",
       "      <th>p10_lda_deadites</th>\n",
       "      <th>p11_lda_idea</th>\n",
       "      <th>p12_lda_love</th>\n",
       "      <th>p13_lda_sense</th>\n",
       "      <th>p14_lda_biomolecular</th>\n",
       "      <th>p15_lda_thee</th>\n",
       "      <th>a_num</th>\n",
       "      <th>p_num</th>\n",
       "      <th>s_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012852</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>-0.009460</td>\n",
       "      <td>-0.001825</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>-0.012019</td>\n",
       "      <td>-0.005941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.267877</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014496</td>\n",
       "      <td>-0.015362</td>\n",
       "      <td>-0.008466</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.147549</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005569</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>-0.012309</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.147652</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012320</td>\n",
       "      <td>-0.007913</td>\n",
       "      <td>-0.014627</td>\n",
       "      <td>-0.005808</td>\n",
       "      <td>-0.004552</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>-0.012969</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>-0.009841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>-0.003734</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>-0.003850</td>\n",
       "      <td>-0.011094</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    s_vec_0   s_vec_1   s_vec_2   s_vec_3   s_vec_4   s_vec_5   s_vec_6  \\\n",
       "0  0.012852 -0.000564  0.000924  0.015578 -0.009460 -0.001825  0.006729   \n",
       "1  0.014496 -0.015362 -0.008466  0.012413  0.012671 -0.000903  0.015530   \n",
       "2 -0.005569  0.010911  0.007000  0.004631  0.000567  0.012376  0.001706   \n",
       "3  0.012320 -0.007913 -0.014627 -0.005808 -0.004552  0.002174 -0.012969   \n",
       "4  0.001876 -0.003734 -0.006766 -0.008286  0.006277 -0.012269 -0.003850   \n",
       "\n",
       "    s_vec_7   s_vec_8   s_vec_9  ...    p9_lda_civil  p10_lda_deadites  \\\n",
       "0  0.014028 -0.012019 -0.005941  ...        0.012556          0.012556   \n",
       "1 -0.005830 -0.007259  0.014899  ...        0.011455          0.011455   \n",
       "2 -0.012309  0.000371  0.012049  ...        0.011455          0.011455   \n",
       "3  0.000185 -0.009987 -0.009841  ...        0.012644          0.012644   \n",
       "4 -0.011094  0.013328  0.011740  ...        0.015147          0.015147   \n",
       "\n",
       "   p11_lda_idea  p12_lda_love  p13_lda_sense  p14_lda_biomolecular  \\\n",
       "0      0.012556      0.012556       0.267877              0.012556   \n",
       "1      0.147549      0.011455       0.011455              0.011455   \n",
       "2      0.147652      0.011455       0.011455              0.011455   \n",
       "3      0.012644      0.012644       0.012644              0.012644   \n",
       "4      0.015147      0.015147       0.015148              0.015147   \n",
       "\n",
       "   p15_lda_thee  a_num  p_num  s_num  \n",
       "0      0.012556      0      0      0  \n",
       "1      0.011455      0      1      0  \n",
       "2      0.011455      0      1      1  \n",
       "3      0.012644      0      2      0  \n",
       "4      0.015147      0      3      0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_vec_0</th>\n",
       "      <th>s_vec_1</th>\n",
       "      <th>s_vec_2</th>\n",
       "      <th>s_vec_3</th>\n",
       "      <th>s_vec_4</th>\n",
       "      <th>s_vec_5</th>\n",
       "      <th>s_vec_6</th>\n",
       "      <th>s_vec_7</th>\n",
       "      <th>s_vec_8</th>\n",
       "      <th>s_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>p9_lda_civil</th>\n",
       "      <th>p10_lda_deadites</th>\n",
       "      <th>p11_lda_idea</th>\n",
       "      <th>p12_lda_love</th>\n",
       "      <th>p13_lda_sense</th>\n",
       "      <th>p14_lda_biomolecular</th>\n",
       "      <th>p15_lda_thee</th>\n",
       "      <th>a_num</th>\n",
       "      <th>p_num</th>\n",
       "      <th>s_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>-0.006734</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>-0.008400</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>-0.010349</td>\n",
       "      <td>-0.011043</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.007921</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.201526</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>0.012661</td>\n",
       "      <td>-0.008760</td>\n",
       "      <td>-0.008574</td>\n",
       "      <td>-0.010942</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>-0.014053</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>0.201952</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>-0.015370</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>-0.009113</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.010596</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>-0.007208</td>\n",
       "      <td>-0.006414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029009</td>\n",
       "      <td>0.201803</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>-0.002627</td>\n",
       "      <td>-0.011851</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>-0.002608</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>-0.013032</td>\n",
       "      <td>-0.010604</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>-0.007297</td>\n",
       "      <td>-0.007836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.466041</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.247581</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>-0.004780</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.004119</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>-0.005124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.465861</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.247772</td>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       s_vec_0   s_vec_1   s_vec_2   s_vec_3   s_vec_4   s_vec_5   s_vec_6  \\\n",
       "7930 -0.006734  0.011162  0.009488 -0.008400 -0.010261 -0.010349 -0.011043   \n",
       "7931  0.012661 -0.008760 -0.008574 -0.010942  0.009893 -0.002269 -0.000573   \n",
       "7932 -0.015370  0.013310 -0.009113  0.002124 -0.010596 -0.002114  0.003677   \n",
       "7933 -0.002627 -0.011851  0.002627 -0.002608  0.009272 -0.013032 -0.010604   \n",
       "7934 -0.004780 -0.000294 -0.002042  0.013785  0.015297 -0.000199 -0.004119   \n",
       "\n",
       "       s_vec_7   s_vec_8   s_vec_9  ...    p9_lda_civil  p10_lda_deadites  \\\n",
       "7930  0.010268 -0.007921 -0.014453  ...        0.000000          0.000000   \n",
       "7931 -0.009278 -0.014053 -0.005179  ...        0.000000          0.000000   \n",
       "7932  0.011908 -0.007208 -0.006414  ...        0.000000          0.000000   \n",
       "7933  0.009540 -0.007297 -0.007836  ...        0.012244          0.012244   \n",
       "7934 -0.002273  0.001138 -0.005124  ...        0.012244          0.012244   \n",
       "\n",
       "      p11_lda_idea  p12_lda_love  p13_lda_sense  p14_lda_biomolecular  \\\n",
       "7930      0.000000      0.158337       0.000000              0.029041   \n",
       "7931      0.000000      0.158665       0.000000              0.028997   \n",
       "7932      0.000000      0.158550       0.000000              0.029009   \n",
       "7933      0.012244      0.466041       0.012244              0.012244   \n",
       "7934      0.012244      0.465861       0.012244              0.012244   \n",
       "\n",
       "      p15_lda_thee  a_num  p_num  s_num  \n",
       "7930      0.201526     16     83      1  \n",
       "7931      0.201952     16     83      2  \n",
       "7932      0.201803     16     83      3  \n",
       "7933      0.247581     16     84      0  \n",
       "7934      0.247772     16     84      1  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prep_train.drop(['a_num'], axis=1)\n",
    "X_test = prep_test.drop(['a_num'], axis=1)\n",
    "y_train = prep_train.a_num\n",
    "y_train_d = pd.get_dummies(prep_train['a_num'])\n",
    "y_test = prep_test.a_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_y = prep_test.a_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     2407\n",
       "13     720\n",
       "9      663\n",
       "14     549\n",
       "16     515\n",
       "10     438\n",
       "15     410\n",
       "12     346\n",
       "4      333\n",
       "2      329\n",
       "3      307\n",
       "0      230\n",
       "11     175\n",
       "1      160\n",
       "6      131\n",
       "8      130\n",
       "7       92\n",
       "Name: a_num, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_y += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_y.loc[adj_y[adj_y<=18].index] -= 1 # Sun Tzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_y.loc[adj_y[adj_y<=8].index] -= 1 # Khayyam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_y.loc[adj_y[adj_y<=4].index] -= 1 # Hobbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  5,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16, 17, 19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_d = pd.get_dummies(adj_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nums = [4,8,18]\n",
    "for num in add_nums:\n",
    "    y_test_d[num] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   5   6   7   9   10  11  12  13  14  15  16  17  19  4   8   \\\n",
       "0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "4   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   18  \n",
       "0   0  \n",
       "1   0  \n",
       "2   0  \n",
       "3   0  \n",
       "4   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_d = y_test_d[list(range(20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935, 98)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Standardize and Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize X Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932, 98)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935, 98)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: a_num, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: a_num, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {i:val for i, val in y_train.value_counts(sort=False).iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1111,\n",
       " 1: 1955,\n",
       " 2: 1205,\n",
       " 3: 569,\n",
       " 4: 6160,\n",
       " 5: 1566,\n",
       " 6: 2492,\n",
       " 7: 6067,\n",
       " 8: 224,\n",
       " 9: 8417,\n",
       " 10: 1159,\n",
       " 11: 7556,\n",
       " 12: 5497,\n",
       " 13: 3982,\n",
       " 14: 2631,\n",
       " 15: 3171,\n",
       " 16: 3426,\n",
       " 17: 3910,\n",
       " 18: 1715,\n",
       " 19: 1119}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Logistic Regression Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_single = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty='l2', random_state=211, n_jobs=3, \n",
    "                            multi_class='multinomial', solver='lbfgs', \n",
    "                            class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932, 98)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63932,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=3, penalty='l2',\n",
       "          random_state=211, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_single['train_accuracy'] = logreg.score(X_train_sc, y_train)\n",
    "lr_single['test_accuracy'] = logreg.score(X_test_sc, y_test)\n",
    "lr_single['params'] = {'penalty':logreg.penalty, 'C':logreg.C, 'solver':logreg.solver}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': 0.5724832634674342,\n",
       " 'test_accuracy': 0.14984247006931317,\n",
       " 'params': {'penalty': 'l2', 'C': 1.0, 'solver': 'lbfgs'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Logistic Regression Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_single = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'penalty':['l2'],\n",
    "    'C':np.arange(.005, .05, .001),\n",
    "    'solver':['lbfgs'],\n",
    "    'class_weight':['balanced'],\n",
    "    'multi_class':['multinomial'],\n",
    "    'n_jobs':[3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(logreg, lr_params, cv=3)\n",
    "grid.fit(X_train_sc, y_train)\n",
    "lr_single['train_accuracy'] = grid.score(X_train_sc, y_train)\n",
    "lr_single['test_accuracy'] = grid.score(X_test_sc, y_test)\n",
    "lr_single['params'] = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = lr_runs.append(lr_single, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.569199</td>\n",
       "      <td>0.148834</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'multi_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.553588</td>\n",
       "      <td>0.144549</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546049</td>\n",
       "      <td>0.146314</td>\n",
       "      <td>{'C': 0.005, 'class_weight': 'balanced', 'mult...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.569199       0.148834   \n",
       "1        0.553588       0.144549   \n",
       "2        0.546049       0.146314   \n",
       "\n",
       "                                              params  \n",
       "0  {'C': 0.1, 'class_weight': 'balanced', 'multi_...  \n",
       "1  {'C': 0.01, 'class_weight': 'balanced', 'multi...  \n",
       "2  {'C': 0.005, 'class_weight': 'balanced', 'mult...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=0.1, penalty='l2', random_state=211, n_jobs=3, \n",
    "                            multi_class='multinomial', solver='lbfgs', \n",
    "                            class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=3, penalty='l2',\n",
       "          random_state=211, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14883427851291745"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Final Logistic Regression to Disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/logreg']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(logreg, '../models/logreg')\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "#logreg = joblib.load('./models/logreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Recurrent Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Keras FFRNN Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_pct = .25\n",
    "dense_1_nodes = 64\n",
    "dense_2_nodes = 128\n",
    "dense_3_nodes = 64\n",
    "target_nodes = 20\n",
    "epochs = 50\n",
    "batch_size = 1000\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train_sc.shape[0], input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "model.add(Dropout(rate=dropout_pct))\n",
    "model.add(Dense(dense_1_nodes, activation='relu'))\n",
    "model.add(Dropout(rate=dropout_pct))\n",
    "model.add(Dense(dense_2_nodes, activation='relu'))\n",
    "model.add(Dropout(rate=dropout_pct))\n",
    "model.add(Dense(dense_3_nodes, activation='relu'))\n",
    "model.add(Dense(y_test_d.shape[1], activation=None))\n",
    "model.add(Activation(tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 63932 samples, validate on 7935 samples\n",
      "Epoch 1/50\n",
      "63932/63932 [==============================] - 9s 142us/step - loss: 7324.1542 - acc: 0.4097 - val_loss: 3.1172 - val_acc: 0.1061\n",
      "Epoch 2/50\n",
      "63932/63932 [==============================] - 7s 113us/step - loss: 5533.5788 - acc: 0.5070 - val_loss: 3.2161 - val_acc: 0.1086\n",
      "Epoch 3/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 5000.9352 - acc: 0.5387 - val_loss: 3.1638 - val_acc: 0.1183\n",
      "Epoch 4/50\n",
      "63932/63932 [==============================] - 7s 113us/step - loss: 4610.8830 - acc: 0.5653 - val_loss: 3.0923 - val_acc: 0.1318\n",
      "Epoch 5/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 4314.5498 - acc: 0.5843 - val_loss: 3.2689 - val_acc: 0.1395\n",
      "Epoch 6/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 3994.5395 - acc: 0.6041 - val_loss: 3.3451 - val_acc: 0.1207\n",
      "Epoch 7/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 3769.3244 - acc: 0.6182 - val_loss: 3.5595 - val_acc: 0.1352\n",
      "Epoch 8/50\n",
      "63932/63932 [==============================] - 7s 113us/step - loss: 3642.7389 - acc: 0.6284 - val_loss: 3.6390 - val_acc: 0.1244\n",
      "Epoch 9/50\n",
      "63932/63932 [==============================] - 7s 113us/step - loss: 3432.8512 - acc: 0.6438 - val_loss: 3.6010 - val_acc: 0.1221\n",
      "Epoch 10/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 3236.1308 - acc: 0.6564 - val_loss: 3.5767 - val_acc: 0.1425\n",
      "Epoch 11/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 3082.2756 - acc: 0.6671 - val_loss: 3.8700 - val_acc: 0.1302\n",
      "Epoch 12/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 2935.1604 - acc: 0.6789 - val_loss: 4.0242 - val_acc: 0.1220\n",
      "Epoch 13/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 2784.0252 - acc: 0.6933 - val_loss: 4.1369 - val_acc: 0.1080\n",
      "Epoch 14/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2739.7040 - acc: 0.6955 - val_loss: 4.1100 - val_acc: 0.1293\n",
      "Epoch 15/50\n",
      "63932/63932 [==============================] - 7s 116us/step - loss: 2586.0228 - acc: 0.7085 - val_loss: 3.9126 - val_acc: 0.1398\n",
      "Epoch 16/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2474.0085 - acc: 0.7177 - val_loss: 4.2443 - val_acc: 0.1304\n",
      "Epoch 17/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2367.4778 - acc: 0.7252 - val_loss: 4.2494 - val_acc: 0.1293\n",
      "Epoch 18/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2268.0460 - acc: 0.7347 - val_loss: 4.2284 - val_acc: 0.1486\n",
      "Epoch 19/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2148.3005 - acc: 0.7450 - val_loss: 4.4459 - val_acc: 0.1360\n",
      "Epoch 20/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2146.2883 - acc: 0.7477 - val_loss: 4.5117 - val_acc: 0.1337\n",
      "Epoch 21/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2089.4013 - acc: 0.7536 - val_loss: 4.4854 - val_acc: 0.1422\n",
      "Epoch 22/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 2033.3079 - acc: 0.7585 - val_loss: 4.6854 - val_acc: 0.1284\n",
      "Epoch 23/50\n",
      "63932/63932 [==============================] - 7s 115us/step - loss: 1885.1645 - acc: 0.7682 - val_loss: 4.4592 - val_acc: 0.1456\n",
      "Epoch 24/50\n",
      "63932/63932 [==============================] - 7s 114us/step - loss: 1859.2187 - acc: 0.7707 - val_loss: 4.3033 - val_acc: 0.1464\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_sc, \n",
    "                    y_train_d, \n",
    "                    validation_data=(X_test_sc, y_test_d), \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[early_stop], \n",
    "                    class_weight=class_weights\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Class Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6b187f1160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Keras FFRNN Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout percentage searched manually over terms:\n",
    "\n",
    "`.5, .45, .4, .35, .3, .25, .2, .15, .1, .05, 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_opt_params = {\n",
    "    'dropout_pct' : [0],\n",
    "    'dense_1_nodes' : [128, 256],\n",
    "    'dense_2_nodes' : [64, 128],\n",
    "    'dense_3_nodes' : [32, 64],\n",
    "    'target_nodes' : [20],\n",
    "    'epochs' : [30],\n",
    "    'batch_size' : [1000],\n",
    "    'patience' : [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_pct         0.0\n",
      "dense_1_nodes     128.0\n",
      "dense_2_nodes      64.0\n",
      "dense_3_nodes      32.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.7979399992676659\n",
      "Val Acc: 0.15107750458972646\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     128.0\n",
      "dense_2_nodes      64.0\n",
      "dense_3_nodes      64.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.7127041231162358\n",
      "Val Acc: 0.14691871389695024\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     128.0\n",
      "dense_2_nodes     128.0\n",
      "dense_3_nodes      32.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.7555788443471727\n",
      "Val Acc: 0.1500525097400842\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     128.0\n",
      "dense_2_nodes     128.0\n",
      "dense_3_nodes      64.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.6809090136030661\n",
      "Val Acc: 0.15374921196009483\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     256.0\n",
      "dense_2_nodes      64.0\n",
      "dense_3_nodes      32.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.6251106082938195\n",
      "Val Acc: 0.12503375749342904\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     256.0\n",
      "dense_2_nodes      64.0\n",
      "dense_3_nodes      64.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.6556944438779075\n",
      "Val Acc: 0.1374381132942313\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     256.0\n",
      "dense_2_nodes     128.0\n",
      "dense_3_nodes      32.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.8004936172519639\n",
      "Val Acc: 0.15091698977096635\n",
      "dropout_pct         0.0\n",
      "dense_1_nodes     256.0\n",
      "dense_2_nodes     128.0\n",
      "dense_3_nodes      64.0\n",
      "target_nodes       20.0\n",
      "epochs             30.0\n",
      "batch_size       1000.0\n",
      "patience            5.0\n",
      "dtype: float64\n",
      "Acc: 0.7253394223844734\n",
      "Val Acc: 0.15579079931112455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout_pct</th>\n",
       "      <th>dense_1_nodes</th>\n",
       "      <th>dense_2_nodes</th>\n",
       "      <th>dense_3_nodes</th>\n",
       "      <th>target_nodes</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>patience</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[7000.47649736732, 4675.093412697035, 3971.401...</td>\n",
       "      <td>[3.2396667289072867, 3.2491806166383856, 3.355...</td>\n",
       "      <td>[0.4410623776004057, 0.571231932609645, 0.6182...</td>\n",
       "      <td>[0.11644612221257372, 0.11291745199664029, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6411.526916538275, 4326.956224729009, 3750.69...</td>\n",
       "      <td>[3.2980531997175886, 3.3142742964931458, 3.365...</td>\n",
       "      <td>[0.47545829559410346, 0.591738094907898, 0.635...</td>\n",
       "      <td>[0.11770636534814799, 0.1257718953068668, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6981.225339276497, 4677.000521641891, 4014.63...</td>\n",
       "      <td>[3.30319941892666, 3.2115299261510186, 3.35187...</td>\n",
       "      <td>[0.4546549452488215, 0.5768629154544117, 0.616...</td>\n",
       "      <td>[0.12665406417127442, 0.13232514326928374, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6289.711426636651, 4343.899238827485, 3696.32...</td>\n",
       "      <td>[3.3623245672828084, 3.6025079355798733, 3.438...</td>\n",
       "      <td>[0.4719858592271111, 0.5880310307163354, 0.637...</td>\n",
       "      <td>[0.13585381371467348, 0.11052299959781077, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[7743.777058382099, 4915.8313539556675, 4134.4...</td>\n",
       "      <td>[3.6170854648104536, 3.243385871702121, 3.5585...</td>\n",
       "      <td>[0.43496214673818107, 0.5569980636426447, 0.60...</td>\n",
       "      <td>[0.11039697907210129, 0.13144297359444357, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout_pct  dense_1_nodes  dense_2_nodes  dense_3_nodes  target_nodes  \\\n",
       "0          0.0          128.0           64.0           32.0          20.0   \n",
       "1          0.0          128.0           64.0           64.0          20.0   \n",
       "2          0.0          128.0          128.0           32.0          20.0   \n",
       "3          0.0          128.0          128.0           64.0          20.0   \n",
       "4          0.0          256.0           64.0           32.0          20.0   \n",
       "\n",
       "   epochs  batch_size  patience  \\\n",
       "0    30.0      1000.0       5.0   \n",
       "1    30.0      1000.0       5.0   \n",
       "2    30.0      1000.0       5.0   \n",
       "3    30.0      1000.0       5.0   \n",
       "4    30.0      1000.0       5.0   \n",
       "\n",
       "                                          train_loss  \\\n",
       "0  [7000.47649736732, 4675.093412697035, 3971.401...   \n",
       "1  [6411.526916538275, 4326.956224729009, 3750.69...   \n",
       "2  [6981.225339276497, 4677.000521641891, 4014.63...   \n",
       "3  [6289.711426636651, 4343.899238827485, 3696.32...   \n",
       "4  [7743.777058382099, 4915.8313539556675, 4134.4...   \n",
       "\n",
       "                                           test_loss  \\\n",
       "0  [3.2396667289072867, 3.2491806166383856, 3.355...   \n",
       "1  [3.2980531997175886, 3.3142742964931458, 3.365...   \n",
       "2  [3.30319941892666, 3.2115299261510186, 3.35187...   \n",
       "3  [3.3623245672828084, 3.6025079355798733, 3.438...   \n",
       "4  [3.6170854648104536, 3.243385871702121, 3.5585...   \n",
       "\n",
       "                                           train_acc  \\\n",
       "0  [0.4410623776004057, 0.571231932609645, 0.6182...   \n",
       "1  [0.47545829559410346, 0.591738094907898, 0.635...   \n",
       "2  [0.4546549452488215, 0.5768629154544117, 0.616...   \n",
       "3  [0.4719858592271111, 0.5880310307163354, 0.637...   \n",
       "4  [0.43496214673818107, 0.5569980636426447, 0.60...   \n",
       "\n",
       "                                            test_acc  \n",
       "0  [0.11644612221257372, 0.11291745199664029, 0.1...  \n",
       "1  [0.11770636534814799, 0.1257718953068668, 0.15...  \n",
       "2  [0.12665406417127442, 0.13232514326928374, 0.1...  \n",
       "3  [0.13585381371467348, 0.11052299959781077, 0.1...  \n",
       "4  [0.11039697907210129, 0.13144297359444357, 0.1...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_df = pd.DataFrame(columns=['dropout_pct','dense_1_nodes','dense_2_nodes',\n",
    "                               'dense_3_nodes','target_nodes','epochs','batch_size',\n",
    "                               'patience'])\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for dp in rnn_opt_params['dropout_pct']:\n",
    "    for d1 in rnn_opt_params['dense_1_nodes']:\n",
    "        for d2 in rnn_opt_params['dense_2_nodes']:\n",
    "            for d3 in rnn_opt_params['dense_3_nodes']:\n",
    "                for tn in rnn_opt_params['target_nodes']:\n",
    "                    for e in rnn_opt_params['epochs']:\n",
    "                        for bs in rnn_opt_params['batch_size']:\n",
    "                            for p in rnn_opt_params['patience']:\n",
    "                                temp_df = pd.Series(index=['dropout_pct','dense_1_nodes','dense_2_nodes',\n",
    "                                                                'dense_3_nodes','target_nodes','epochs',\n",
    "                                                                'batch_size','patience'])\n",
    "                                temp_df['dropout_pct'] = dp\n",
    "                                temp_df['dense_1_nodes'] = d1\n",
    "                                temp_df['dense_2_nodes'] = d2\n",
    "                                temp_df['dense_3_nodes'] = d3\n",
    "                                temp_df['target_nodes'] = tn\n",
    "                                temp_df['epochs'] = e\n",
    "                                temp_df['batch_size'] = bs\n",
    "                                temp_df['patience'] = p\n",
    "                                \n",
    "                                model = Sequential()\n",
    "                                model.add(Dense(X_train_sc.shape[0], input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "                                model.add(Dropout(rate=dp))\n",
    "                                model.add(Dense(d1, activation='relu'))\n",
    "                                model.add(Dropout(rate=dp))\n",
    "                                model.add(Dense(d2, activation='relu'))\n",
    "                                model.add(Dropout(rate=dp))\n",
    "                                model.add(Dense(d3, activation='relu'))\n",
    "                                model.add(Dense(y_test_d.shape[1], activation=None))\n",
    "                                model.add(Activation(tf.nn.softmax))\n",
    "                                model.compile(loss='categorical_crossentropy', \n",
    "                                              optimizer='adam', \n",
    "                                              metrics=['accuracy'], \n",
    "                                              weighted_metrics=['accuracy'])\n",
    "                                early_stop = EarlyStopping(monitor='val_acc', \n",
    "                                                                min_delta=0, patience=p, \n",
    "                                                                verbose=0, mode='auto')\n",
    "                                history = model.fit(X_train_sc, \n",
    "                                                    y_train_d, \n",
    "                                                    validation_data=(X_test_sc, y_test_d), \n",
    "                                                    epochs=e, \n",
    "                                                    batch_size=bs, \n",
    "                                                    callbacks=[early_stop], \n",
    "                                                    class_weight=class_weights, \n",
    "                                                    verbose=0)\n",
    "                                \n",
    "                                train_loss_list.append(history.history['loss'])\n",
    "                                test_loss_list.append(history.history['val_loss'])\n",
    "                                train_acc_list.append(history.history['acc'])\n",
    "                                test_acc_list.append(history.history['val_acc'])\n",
    "                                \n",
    "                                rnn_df = rnn_df.append(temp_df, ignore_index=True)\n",
    "                                print(temp_df)\n",
    "                                print('Acc:',np.mean(history.history['acc']))\n",
    "                                print('Val Acc:',np.mean(history.history['val_acc']))\n",
    "\n",
    "rnn_df['train_loss'] = train_loss_list\n",
    "rnn_df['test_loss'] = test_loss_list\n",
    "rnn_df['train_acc'] = train_acc_list\n",
    "rnn_df['test_acc'] = test_acc_list\n",
    "rnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_runs_df = rnn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_runs_df = rnn_runs_df.append(rnn_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_runs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout_pct</th>\n",
       "      <th>dense_1_nodes</th>\n",
       "      <th>dense_2_nodes</th>\n",
       "      <th>dense_3_nodes</th>\n",
       "      <th>target_nodes</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>patience</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6289.711426636651, 4343.899238827485, 3696.32...</td>\n",
       "      <td>[3.3623245672828084, 3.6025079355798733, 3.438...</td>\n",
       "      <td>[0.4719858592271111, 0.5880310307163354, 0.637...</td>\n",
       "      <td>[0.13585381371467348, 0.11052299959781077, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[7743.777058382099, 4915.8313539556675, 4134.4...</td>\n",
       "      <td>[3.6170854648104536, 3.243385871702121, 3.5585...</td>\n",
       "      <td>[0.43496214673818107, 0.5569980636426447, 0.60...</td>\n",
       "      <td>[0.11039697907210129, 0.13144297359444357, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6351.177239830992, 4421.104237155787, 3779.57...</td>\n",
       "      <td>[3.4931962210649803, 3.091948292130709, 3.6197...</td>\n",
       "      <td>[0.47222048397271704, 0.5856065827653233, 0.63...</td>\n",
       "      <td>[0.10560806609558736, 0.18323881179094315, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6742.465438742531, 4611.957481771404, 3943.60...</td>\n",
       "      <td>[3.386409793173508, 3.2864797131851473, 3.4490...</td>\n",
       "      <td>[0.4582525178750935, 0.5785052836526807, 0.625...</td>\n",
       "      <td>[0.1214870806506447, 0.12488972678048174, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6236.77191583318, 4300.025955311894, 3648.506...</td>\n",
       "      <td>[3.3483060630673345, 3.270634562547055, 3.5625...</td>\n",
       "      <td>[0.4777419780118403, 0.5934273885828841, 0.641...</td>\n",
       "      <td>[0.13774416709780016, 0.13547573766301996, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout_pct  dense_1_nodes  dense_2_nodes  dense_3_nodes  target_nodes  \\\n",
       "83          0.0          128.0          128.0           64.0          20.0   \n",
       "84          0.0          256.0           64.0           32.0          20.0   \n",
       "85          0.0          256.0           64.0           64.0          20.0   \n",
       "86          0.0          256.0          128.0           32.0          20.0   \n",
       "87          0.0          256.0          128.0           64.0          20.0   \n",
       "\n",
       "    epochs  batch_size  patience  \\\n",
       "83    30.0      1000.0       5.0   \n",
       "84    30.0      1000.0       5.0   \n",
       "85    30.0      1000.0       5.0   \n",
       "86    30.0      1000.0       5.0   \n",
       "87    30.0      1000.0       5.0   \n",
       "\n",
       "                                           train_loss  \\\n",
       "83  [6289.711426636651, 4343.899238827485, 3696.32...   \n",
       "84  [7743.777058382099, 4915.8313539556675, 4134.4...   \n",
       "85  [6351.177239830992, 4421.104237155787, 3779.57...   \n",
       "86  [6742.465438742531, 4611.957481771404, 3943.60...   \n",
       "87  [6236.77191583318, 4300.025955311894, 3648.506...   \n",
       "\n",
       "                                            test_loss  \\\n",
       "83  [3.3623245672828084, 3.6025079355798733, 3.438...   \n",
       "84  [3.6170854648104536, 3.243385871702121, 3.5585...   \n",
       "85  [3.4931962210649803, 3.091948292130709, 3.6197...   \n",
       "86  [3.386409793173508, 3.2864797131851473, 3.4490...   \n",
       "87  [3.3483060630673345, 3.270634562547055, 3.5625...   \n",
       "\n",
       "                                            train_acc  \\\n",
       "83  [0.4719858592271111, 0.5880310307163354, 0.637...   \n",
       "84  [0.43496214673818107, 0.5569980636426447, 0.60...   \n",
       "85  [0.47222048397271704, 0.5856065827653233, 0.63...   \n",
       "86  [0.4582525178750935, 0.5785052836526807, 0.625...   \n",
       "87  [0.4777419780118403, 0.5934273885828841, 0.641...   \n",
       "\n",
       "                                             test_acc  \n",
       "83  [0.13585381371467348, 0.11052299959781077, 0.1...  \n",
       "84  [0.11039697907210129, 0.13144297359444357, 0.1...  \n",
       "85  [0.10560806609558736, 0.18323881179094315, 0.1...  \n",
       "86  [0.1214870806506447, 0.12488972678048174, 0.13...  \n",
       "87  [0.13774416709780016, 0.13547573766301996, 0.1...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_runs_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save RNN Results DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_runs_df.to_csv('../models/rnn_runs_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load RNN Results DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout_pct</th>\n",
       "      <th>dense_1_nodes</th>\n",
       "      <th>dense_2_nodes</th>\n",
       "      <th>dense_3_nodes</th>\n",
       "      <th>target_nodes</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>patience</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6289.711426636651, 4343.899238827485, 3696.32...</td>\n",
       "      <td>[3.3623245672828084, 3.6025079355798733, 3.438...</td>\n",
       "      <td>[0.4719858592271111, 0.5880310307163354, 0.637...</td>\n",
       "      <td>[0.13585381371467348, 0.11052299959781077, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[7743.777058382099, 4915.8313539556675, 4134.4...</td>\n",
       "      <td>[3.6170854648104536, 3.243385871702121, 3.5585...</td>\n",
       "      <td>[0.43496214673818107, 0.5569980636426447, 0.60...</td>\n",
       "      <td>[0.11039697907210129, 0.13144297359444357, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6351.177239830992, 4421.104237155787, 3779.57...</td>\n",
       "      <td>[3.4931962210649803, 3.091948292130709, 3.6197...</td>\n",
       "      <td>[0.47222048397271704, 0.5856065827653233, 0.63...</td>\n",
       "      <td>[0.10560806609558736, 0.18323881179094315, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6742.465438742531, 4611.957481771404, 3943.60...</td>\n",
       "      <td>[3.386409793173508, 3.2864797131851473, 3.4490...</td>\n",
       "      <td>[0.4582525178750935, 0.5785052836526807, 0.625...</td>\n",
       "      <td>[0.1214870806506447, 0.12488972678048174, 0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6236.77191583318, 4300.025955311894, 3648.506...</td>\n",
       "      <td>[3.3483060630673345, 3.270634562547055, 3.5625...</td>\n",
       "      <td>[0.4777419780118403, 0.5934273885828841, 0.641...</td>\n",
       "      <td>[0.13774416709780016, 0.13547573766301996, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout_pct  dense_1_nodes  dense_2_nodes  dense_3_nodes  target_nodes  \\\n",
       "83          0.0          128.0          128.0           64.0          20.0   \n",
       "84          0.0          256.0           64.0           32.0          20.0   \n",
       "85          0.0          256.0           64.0           64.0          20.0   \n",
       "86          0.0          256.0          128.0           32.0          20.0   \n",
       "87          0.0          256.0          128.0           64.0          20.0   \n",
       "\n",
       "    epochs  batch_size  patience  \\\n",
       "83    30.0      1000.0       5.0   \n",
       "84    30.0      1000.0       5.0   \n",
       "85    30.0      1000.0       5.0   \n",
       "86    30.0      1000.0       5.0   \n",
       "87    30.0      1000.0       5.0   \n",
       "\n",
       "                                           train_loss  \\\n",
       "83  [6289.711426636651, 4343.899238827485, 3696.32...   \n",
       "84  [7743.777058382099, 4915.8313539556675, 4134.4...   \n",
       "85  [6351.177239830992, 4421.104237155787, 3779.57...   \n",
       "86  [6742.465438742531, 4611.957481771404, 3943.60...   \n",
       "87  [6236.77191583318, 4300.025955311894, 3648.506...   \n",
       "\n",
       "                                            test_loss  \\\n",
       "83  [3.3623245672828084, 3.6025079355798733, 3.438...   \n",
       "84  [3.6170854648104536, 3.243385871702121, 3.5585...   \n",
       "85  [3.4931962210649803, 3.091948292130709, 3.6197...   \n",
       "86  [3.386409793173508, 3.2864797131851473, 3.4490...   \n",
       "87  [3.3483060630673345, 3.270634562547055, 3.5625...   \n",
       "\n",
       "                                            train_acc  \\\n",
       "83  [0.4719858592271111, 0.5880310307163354, 0.637...   \n",
       "84  [0.43496214673818107, 0.5569980636426447, 0.60...   \n",
       "85  [0.47222048397271704, 0.5856065827653233, 0.63...   \n",
       "86  [0.4582525178750935, 0.5785052836526807, 0.625...   \n",
       "87  [0.4777419780118403, 0.5934273885828841, 0.641...   \n",
       "\n",
       "                                             test_acc  \n",
       "83  [0.13585381371467348, 0.11052299959781077, 0.1...  \n",
       "84  [0.11039697907210129, 0.13144297359444357, 0.1...  \n",
       "85  [0.10560806609558736, 0.18323881179094315, 0.1...  \n",
       "86  [0.1214870806506447, 0.12488972678048174, 0.13...  \n",
       "87  [0.13774416709780016, 0.13547573766301996, 0.1...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn_runs_df = pd.read_csv('../models/rnn_runs_df.csv')\n",
    "rnn_runs_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-run with Next Hyperparameter HERE --^**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.07208569589168978, 0.06452426048102493, 0.0...\n",
       "1    [0.07536232139311952, 0.08128544497030782, 0.1...\n",
       "2    [0.06175173280635061, 0.08998109674328855, 0.0...\n",
       "3    [0.059861371879921854, 0.07561436773200943, 0....\n",
       "4    [0.06402016511549627, 0.09023314575936409, 0.1...\n",
       "Name: test_acc, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_runs_df['test_acc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "\n",
    "for r, result in rnn_runs_df['test_acc'].iteritems():\n",
    "    eval_results.append(ast.literal_eval(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = []\n",
    "\n",
    "for r, result in rnn_runs_df['train_acc'].iteritems():\n",
    "    train_results.append(ast.literal_eval(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488705</td>\n",
       "      <td>0.558844</td>\n",
       "      <td>0.10289</td>\n",
       "      <td>0.129175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555824</td>\n",
       "      <td>0.633329</td>\n",
       "      <td>0.10648</td>\n",
       "      <td>0.120605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487546</td>\n",
       "      <td>0.55789</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>0.119471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51138</td>\n",
       "      <td>0.580554</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>0.118336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.574122</td>\n",
       "      <td>0.660389</td>\n",
       "      <td>0.114382</td>\n",
       "      <td>0.133207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_mean train_max test_mean  test_max\n",
       "0   0.488705  0.558844   0.10289  0.129175\n",
       "1   0.555824  0.633329   0.10648  0.120605\n",
       "2   0.487546   0.55789  0.103914  0.119471\n",
       "3    0.51138  0.580554  0.103163  0.118336\n",
       "4   0.574122  0.660389  0.114382  0.133207"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(columns=['train_mean','train_max','test_mean','test_max'])\n",
    "\n",
    "for i, res_list in enumerate(eval_results):\n",
    "    res_df.loc[i, 'test_mean'] = np.mean(res_list)\n",
    "    res_df.loc[i, 'test_max'] = np.max(res_list)\n",
    "    \n",
    "for j, train_list in enumerate(train_results):\n",
    "    res_df.loc[j, 'train_mean'] = np.mean(train_list)\n",
    "    res_df.loc[j, 'train_max'] = np.max(train_list)\n",
    "    \n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.800494</td>\n",
       "      <td>0.942783</td>\n",
       "      <td>0.150917</td>\n",
       "      <td>0.17782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.79794</td>\n",
       "      <td>0.952543</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.175299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.791915</td>\n",
       "      <td>0.920681</td>\n",
       "      <td>0.148396</td>\n",
       "      <td>0.167234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.762288</td>\n",
       "      <td>0.894294</td>\n",
       "      <td>0.143536</td>\n",
       "      <td>0.16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.755579</td>\n",
       "      <td>0.918648</td>\n",
       "      <td>0.150053</td>\n",
       "      <td>0.172275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mean train_max test_mean  test_max\n",
       "86   0.800494  0.942783  0.150917   0.17782\n",
       "80    0.79794  0.952543  0.151078  0.175299\n",
       "78   0.791915  0.920681  0.148396  0.167234\n",
       "62   0.762288  0.894294  0.143536   0.16925\n",
       "82   0.755579  0.918648  0.150053  0.172275"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by='train_mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.79794</td>\n",
       "      <td>0.952543</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.175299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.800494</td>\n",
       "      <td>0.942783</td>\n",
       "      <td>0.150917</td>\n",
       "      <td>0.17782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.791915</td>\n",
       "      <td>0.920681</td>\n",
       "      <td>0.148396</td>\n",
       "      <td>0.167234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.755579</td>\n",
       "      <td>0.918648</td>\n",
       "      <td>0.150053</td>\n",
       "      <td>0.172275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.762288</td>\n",
       "      <td>0.894294</td>\n",
       "      <td>0.143536</td>\n",
       "      <td>0.16925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mean train_max test_mean  test_max\n",
       "80    0.79794  0.952543  0.151078  0.175299\n",
       "86   0.800494  0.942783  0.150917   0.17782\n",
       "78   0.791915  0.920681  0.148396  0.167234\n",
       "82   0.755579  0.918648  0.150053  0.172275\n",
       "62   0.762288  0.894294  0.143536   0.16925"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by='train_max', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.880467</td>\n",
       "      <td>0.155791</td>\n",
       "      <td>0.188784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.680909</td>\n",
       "      <td>0.81668</td>\n",
       "      <td>0.153749</td>\n",
       "      <td>0.175929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.79794</td>\n",
       "      <td>0.952543</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.175299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.800494</td>\n",
       "      <td>0.942783</td>\n",
       "      <td>0.150917</td>\n",
       "      <td>0.17782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.755579</td>\n",
       "      <td>0.918648</td>\n",
       "      <td>0.150053</td>\n",
       "      <td>0.172275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mean train_max test_mean  test_max\n",
       "87   0.725339  0.880467  0.155791  0.188784\n",
       "83   0.680909   0.81668  0.153749  0.175929\n",
       "80    0.79794  0.952543  0.151078  0.175299\n",
       "86   0.800494  0.942783  0.150917   0.17782\n",
       "82   0.755579  0.918648  0.150053  0.172275"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by='test_mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.880467</td>\n",
       "      <td>0.155791</td>\n",
       "      <td>0.188784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.655694</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.137438</td>\n",
       "      <td>0.183239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.712704</td>\n",
       "      <td>0.855737</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.182231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.800494</td>\n",
       "      <td>0.942783</td>\n",
       "      <td>0.150917</td>\n",
       "      <td>0.17782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.652407</td>\n",
       "      <td>0.776309</td>\n",
       "      <td>0.145342</td>\n",
       "      <td>0.177316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_mean train_max test_mean  test_max\n",
       "87   0.725339  0.880467  0.155791  0.188784\n",
       "85   0.655694  0.774338  0.137438  0.183239\n",
       "81   0.712704  0.855737  0.146919  0.182231\n",
       "86   0.800494  0.942783  0.150917   0.17782\n",
       "64   0.652407  0.776309  0.145342  0.177316"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by='test_max', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting run 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest Mean Accuracy Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model number\n",
    "mn = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropout_pct                                                      0\n",
       "dense_1_nodes                                                  256\n",
       "dense_2_nodes                                                  128\n",
       "dense_3_nodes                                                   32\n",
       "target_nodes                                                    20\n",
       "epochs                                                          30\n",
       "batch_size                                                    1000\n",
       "patience                                                         5\n",
       "train_loss       [6742.465438742531, 4611.957481771404, 3943.60...\n",
       "test_loss        [3.386409793173508, 3.2864797131851473, 3.4490...\n",
       "train_acc        [0.4582525178750935, 0.5785052836526807, 0.625...\n",
       "test_acc         [0.1214870806506447, 0.12488972678048174, 0.13...\n",
       "Name: 86, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_runs_df.loc[mn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropout_pct                                                      0\n",
       "dense_1_nodes                                                  256\n",
       "dense_2_nodes                                                  128\n",
       "dense_3_nodes                                                   32\n",
       "target_nodes                                                    20\n",
       "epochs                                                          30\n",
       "batch_size                                                    1000\n",
       "patience                                                         5\n",
       "train_loss       [6742.465438742531, 4611.957481771404, 3943.60...\n",
       "test_loss        [3.386409793173508, 3.2864797131851473, 3.4490...\n",
       "train_acc        [0.4582525178750935, 0.5785052836526807, 0.625...\n",
       "test_acc         [0.1214870806506447, 0.12488972678048174, 0.13...\n",
       "Name: 86, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_runs_df.loc[mn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = rnn_runs_df.loc[mn,'dropout_pct']\n",
    "d1 = rnn_runs_df.loc[mn,'dense_1_nodes'].astype(int)\n",
    "d2 = rnn_runs_df.loc[mn,'dense_2_nodes'].astype(int)\n",
    "d3 = rnn_runs_df.loc[mn,'dense_3_nodes'].astype(int)\n",
    "tn = rnn_runs_df.loc[mn,'target_nodes'].astype(int)\n",
    "e = rnn_runs_df.loc[mn,'epochs'].astype(int)\n",
    "bs = rnn_runs_df.loc[mn,'batch_size'].astype(int)\n",
    "p = rnn_runs_df.loc[mn,'patience'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 256, 128, 32, 20, 30, 1000, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp, d1, d2, d3, tn, e, bs, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 63932 samples, validate on 7935 samples\n",
      "Epoch 1/30\n",
      "63932/63932 [==============================] - 10s 151us/step - loss: 1.6342 - acc: 0.4933 - val_loss: 2.8465 - val_acc: 0.1640\n",
      "Epoch 2/30\n",
      "63932/63932 [==============================] - 8s 121us/step - loss: 1.1570 - acc: 0.6199 - val_loss: 3.0967 - val_acc: 0.1655\n",
      "Epoch 3/30\n",
      "63932/63932 [==============================] - 8s 122us/step - loss: 0.9758 - acc: 0.6740 - val_loss: 3.3011 - val_acc: 0.1701\n",
      "Epoch 4/30\n",
      "63932/63932 [==============================] - 8s 122us/step - loss: 0.8279 - acc: 0.7233 - val_loss: 3.5418 - val_acc: 0.1763\n",
      "Epoch 5/30\n",
      "63932/63932 [==============================] - 8s 122us/step - loss: 0.6944 - acc: 0.7687 - val_loss: 3.9464 - val_acc: 0.1698\n",
      "Epoch 6/30\n",
      "63932/63932 [==============================] - 8s 123us/step - loss: 0.5792 - acc: 0.8074 - val_loss: 4.1354 - val_acc: 0.1822\n",
      "Epoch 7/30\n",
      "63932/63932 [==============================] - 8s 122us/step - loss: 0.4588 - acc: 0.8490 - val_loss: 4.5253 - val_acc: 0.1695\n",
      "Epoch 8/30\n",
      "63932/63932 [==============================] - 8s 123us/step - loss: 0.3632 - acc: 0.8816 - val_loss: 4.8738 - val_acc: 0.1680\n",
      "Epoch 9/30\n",
      "63932/63932 [==============================] - 8s 123us/step - loss: 0.3017 - acc: 0.9021 - val_loss: 5.6758 - val_acc: 0.1498\n",
      "Epoch 10/30\n",
      "63932/63932 [==============================] - 8s 123us/step - loss: 0.2427 - acc: 0.9213 - val_loss: 5.7387 - val_acc: 0.1756\n",
      "Epoch 11/30\n",
      "63932/63932 [==============================] - 8s 124us/step - loss: 0.1976 - acc: 0.9375 - val_loss: 6.1520 - val_acc: 0.1777\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train_sc.shape[0], input_dim=X_train_sc.shape[1], activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(d1, activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(d2, activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(d3, activation='relu'))\n",
    "model.add(Dense(y_test_d.shape[1], activation=None))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                   optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_acc', \n",
    "                                min_delta=0, patience=p, \n",
    "                                verbose=1, mode='auto')\n",
    "history = model.fit(X_train_sc, \n",
    "                    y_train_d, \n",
    "                    validation_data=(X_test_sc, y_test_d), \n",
    "                    epochs=e, \n",
    "                    batch_size=bs, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f28b435f160>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Testing loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f28b42f8d30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history['acc']\n",
    "test_acc = history.history['val_acc']\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(test_acc, label='Testing Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Final Keras FFRNN to Disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorizing Text Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using medium English library which does not include vectors\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_to_df(par_file, nlp=nlp, sw=['the','a','but','like','for'], to_stem=False):\n",
    "#     # Run spaCy process on each paragraph and store docs in list\n",
    "#     print('nlp of paragraphs...')\n",
    "#     par_nlp = []\n",
    "#     for par in tqdm(par_file.paragraph):\n",
    "#         par_nlp.append(nlp(par))\n",
    "    \n",
    "#     # Store paragraph lemma from spaCy docs\n",
    "#     print('nlp lemmatizing, part-of-speech, stopwords...')\n",
    "#     par_lemma = []\n",
    "#     for par in tqdm(par_nlp):\n",
    "#         par_lemma.append([token.lemma_ for token in par     # List comprehension\n",
    "#                            if token.lemma_ != '-PRON-'           # Pronouns are excluded\n",
    "#                            and token.pos_ != 'PUNCT'             # Punctionation is excluded\n",
    "#                            and token.is_alpha                    # Numbers are excluded\n",
    "#                            and not token.is_stop                 # Stop words are excluded\n",
    "#                           and len(token.lemma_) > 1])               \n",
    "    \n",
    "#     # Stem lemma with NLTK PorterStemmer and remove stop words\n",
    "#     print('additional stopwords...')\n",
    "#     if to_stem: ps = PorterStemmer()\n",
    "#     par_lemma_sw = []\n",
    "#     for vec_list in tqdm(par_lemma):    \n",
    "#         update_list = []\n",
    "#         for token in vec_list:\n",
    "#             if token in sw: continue\n",
    "#             if to_stem: update_list.append(ps.stem(token))\n",
    "#             else: update_list.append(token)\n",
    "#         par_lemma_sw.append(update_list)\n",
    "    \n",
    "#     # Run spaCy on each sentence doc: Text\n",
    "#     print('saving sentence text...')\n",
    "#     sent_text = []\n",
    "#     for par in tqdm(par_nlp):\n",
    "#         sent_list = []\n",
    "#         for s in par.sents:\n",
    "#             sent_list.append(s.text)\n",
    "#         sent_text.append(sent_list)\n",
    "    \n",
    "#     # Run spaCy on each sentence doc: NLP\n",
    "#     print('nlp of sentences...')\n",
    "#     sent_nlp = []\n",
    "#     for par in tqdm(par_nlp):\n",
    "#         sent_list = []\n",
    "#         for s in par.sents:\n",
    "#             sent_list.append(nlp(s.text))\n",
    "#         sent_nlp.append(sent_list)\n",
    "    \n",
    "#     # Store lemma from spaCy docs\n",
    "#     print('nlp lemmatizing, part-of-speech, stopwords...')\n",
    "#     sent_lemma = []\n",
    "#     for par in tqdm(sent_nlp):\n",
    "#         for sent in par:\n",
    "#             sent_lemma.append([token.lemma_ for token in sent     # List comprehension\n",
    "#                                if token.lemma_ != '-PRON-'           # Pronouns are excluded\n",
    "#                                and token.pos_ != 'PUNCT'             # Punctionation is excluded\n",
    "#                                and token.is_alpha                    # Numbers are excluded\n",
    "#                                and not token.is_stop                 # Stop words are excluded\n",
    "#                               and len(token.lemma_) > 1])               \n",
    "    \n",
    "#     # Stem lemma with NLTK PorterStemmer and remove stop words\n",
    "#     print('additional stopwords...')\n",
    "#     if to_stem: ps = PorterStemmer()\n",
    "#     sent_lemma_sw = []\n",
    "#     for vec_list in tqdm(sent_lemma):    \n",
    "#         update_list = []\n",
    "#         for token in vec_list:\n",
    "#             if token in sw: continue\n",
    "#             if to_stem: update_list.append(ps.stem(token))\n",
    "#             else: update_list.append(token)\n",
    "#         sent_lemma_sw.append(update_list)\n",
    "    \n",
    "#     print('constructing dataframe...')\n",
    "#     nlp_df = pd.DataFrame(columns=['author','work','a_num','w_num','p_num','s_num',\n",
    "#                                     'sent_text','sent_lemma','par_text','par_lemma'])\n",
    "\n",
    "#     a_num = 0\n",
    "#     w_num = 0\n",
    "#     p_num = 0\n",
    "\n",
    "#     for p, sents_in_par in enumerate(tqdm(sent_text)):\n",
    "#         for s, sent in enumerate(sents_in_par):\n",
    "#             nlp_df = nlp_df.append({'author':par_file.loc[p, 'author'], \n",
    "#                                     'work':par_file.loc[p, 'work'], \n",
    "#                                     'a_num':a_num,\n",
    "#                                     'w_num':w_num,\n",
    "#                                     'p_num':p_num,\n",
    "#                                     's_num':s,\n",
    "#                                     'sent_text':sent,\n",
    "#                                     'par_text':par_file.loc[p, 'paragraph'],\n",
    "#                                     'par_lemma':par_lemma_sw[p]\n",
    "#                                     }, ignore_index=True)\n",
    "#         p_num += 1\n",
    "#         if p == par_file.shape[0]-1: continue\n",
    "#         if par_file.loc[p,'work'] != par_file.loc[p+1,'work']:\n",
    "#             p_num = 0\n",
    "#             w_num += 1\n",
    "#             if par_file.loc[p,'author'] != par_file.loc[p+1,'author']:\n",
    "#                 a_num += 1\n",
    "\n",
    "#     nlp_df['sent_lemma'] = sent_lemma_sw\n",
    "#     print('complete')\n",
    "#     return nlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_to_df(par_file, nlp=nlp, sw=['the','a','but','like','for'], to_stem=False):\n",
    "    # Run spaCy process on each paragraph and store docs in list\n",
    "    print('1/8: nlp of paragraphs...')\n",
    "    par_nlp = []\n",
    "    for par in tqdm(par_file.paragraph):\n",
    "        par_nlp.append(nlp(par))\n",
    "    \n",
    "    # Store paragraph lemma from spaCy docs\n",
    "    print('2/8: nlp lemmatizing, part-of-speech, stopwords...')\n",
    "    par_lemma = []\n",
    "    for par in tqdm(par_nlp):\n",
    "        par_lemma.append([token.lemma_ for token in par     # List comprehension\n",
    "                           if token.lemma_ != '-PRON-'           # Pronouns are excluded\n",
    "                           and token.pos_ != 'PUNCT'             # Punctuation is excluded\n",
    "                           and token.is_alpha                    # Numbers are excluded\n",
    "                           and not token.is_stop                 # Stop words are excluded\n",
    "                          and len(token.lemma_) > 1])\n",
    "    par_lemma = [[pl[i].lower() for i in range(len(pl))] for pl in par_lemma]\n",
    "    \n",
    "    # Stem lemma with NLTK PorterStemmer and remove stop words\n",
    "    print('3/8: additional stopwords...')\n",
    "    if to_stem: ps = PorterStemmer()\n",
    "    par_lemma_sw = []\n",
    "    for vec_list in tqdm(par_lemma):    \n",
    "        update_list = []\n",
    "        for token in vec_list:\n",
    "            if token in sw: continue\n",
    "            if to_stem: update_list.append(ps.stem(token))\n",
    "            else: update_list.append(token)\n",
    "        par_lemma_sw.append(update_list)\n",
    "    \n",
    "    # Run spaCy on each sentence doc: Text\n",
    "    print('4/8: saving sentence text...')\n",
    "    sent_text = []\n",
    "    for par in tqdm(par_nlp):\n",
    "        sent_list = []\n",
    "        for s in par.sents:\n",
    "            sent_list.append(s.text)\n",
    "        sent_text.append(sent_list)\n",
    "    \n",
    "    # Run spaCy on each sentence doc: NLP\n",
    "    print('5/8: nlp of sentences...')\n",
    "    sent_nlp = []\n",
    "    for par in tqdm(par_nlp):\n",
    "        sent_list = []\n",
    "        for s in par.sents:\n",
    "            sent_list.append(nlp(s.text))\n",
    "        sent_nlp.append(sent_list)\n",
    "    \n",
    "    # Store lemma from spaCy docs\n",
    "    print('6/8: nlp lemmatizing, part-of-speech, stopwords...')\n",
    "    sent_lemma = []\n",
    "    for par in tqdm(sent_nlp):\n",
    "        for sent in par:\n",
    "            sent_lemma.append([token.lemma_ for token in sent     # List comprehension\n",
    "                               if token.lemma_ != '-PRON-'           # Pronouns are excluded\n",
    "                               and token.pos_ != 'PUNCT'             # Punctuation is excluded\n",
    "                               and token.is_alpha                    # Numbers are excluded\n",
    "                               and not token.is_stop                 # Stop words are excluded\n",
    "                              and len(token.lemma_) > 1])\n",
    "    sent_lemma = [[sl[j].lower() for j in range(len(sl))] for sl in sent_lemma]\n",
    "    \n",
    "    # Stem lemma with NLTK PorterStemmer and remove stop words\n",
    "    print('7/8: additional stopwords...')\n",
    "    if to_stem: ps = PorterStemmer()\n",
    "    sent_lemma_sw = []\n",
    "    for vec_list in tqdm(sent_lemma):    \n",
    "        update_list = []\n",
    "        for token in vec_list:\n",
    "            if token in sw: continue\n",
    "            if to_stem: update_list.append(ps.stem(token))\n",
    "            else: update_list.append(token)\n",
    "        sent_lemma_sw.append(update_list)\n",
    "    \n",
    "    print('8/8: constructing dataframe...')\n",
    "    nlp_df = pd.DataFrame(columns=['author','work','a_num','w_num','p_num','s_num',\n",
    "                                    'sent_text','sent_lemma','par_text','par_lemma'])\n",
    "\n",
    "    a_num = 0\n",
    "    w_num = 0\n",
    "    p_num = 0\n",
    "\n",
    "    for p, sents_in_par in enumerate(tqdm(sent_text)):\n",
    "        for s, sent in enumerate(sents_in_par):\n",
    "            nlp_df = nlp_df.append({'author':par_file.loc[p, 'author'], \n",
    "                                    'work':par_file.loc[p, 'work'], \n",
    "                                    'a_num':a_num,\n",
    "                                    'w_num':w_num,\n",
    "                                    'p_num':p_num,\n",
    "                                    's_num':s,\n",
    "                                    'sent_text':sent,\n",
    "                                    'par_text':par_file.loc[p, 'paragraph'],\n",
    "                                    'par_lemma':par_lemma_sw[p]\n",
    "                                    }, ignore_index=True)\n",
    "        p_num += 1\n",
    "        if p == par_file.shape[0]-1: continue\n",
    "        if par_file.loc[p,'work'] != par_file.loc[p+1,'work']:\n",
    "            p_num = 0\n",
    "            w_num += 1\n",
    "            if par_file.loc[p,'author'] != par_file.loc[p+1,'author']:\n",
    "                a_num += 1\n",
    "\n",
    "    nlp_df['sent_lemma'] = sent_lemma_sw\n",
    "    print('complete')\n",
    "    return nlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_factorize(lda_df, model=model_full, ss=ss):\n",
    "    lda_sc = ss.transform(lda_df.values)    \n",
    "    preds = model.predict_proba(lda_sc)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nlp_factors(preds, raw_text, doc_number=0, thresh=0.01, target_authors=None):\n",
    "    print('-'*30)\n",
    "    print('Doc #:', doc_number)\n",
    "    if target_authors: print('Target Author:', target_authors[doc_number])\n",
    "    print('Text:\\n', raw_text[doc_number])\n",
    "    print('\\nPhilosophical Factors:\\n')\n",
    "    \n",
    "    result_list = [(text_data.Author.unique()[i], preds[doc_number][i]) for i in range(len(text_data.Author.unique()))]\n",
    "    result_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    for j in range(len(text_data.Author.unique())):\n",
    "        n_sp = 35 - len(result_list[j][0])\n",
    "        if result_list[j][1] >= thresh:\n",
    "            print('\\t{}{}{}'.format(result_list[j][0],str(' '*n_sp),str(round(result_list[j][1], 3))))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babbage = \"\"\"\n",
    "There are few circumstances which so strongly distinguish the philosopher, \n",
    "as the calmness with which he can reply to criticisms he may think...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to Notebook 5: Factorizing Unseen Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
